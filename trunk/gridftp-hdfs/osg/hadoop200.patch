diff -ru gridftp-hdfs-0.5.4-orig/conf/gridftp-hdfs-environment gridftp-hdfs-0.5.4/conf/gridftp-hdfs-environment
--- gridftp-hdfs-0.5.4-orig/conf/gridftp-hdfs-environment	2012-07-19 10:39:34.000000000 -0500
+++ gridftp-hdfs-0.5.4/conf/gridftp-hdfs-environment	2012-07-19 15:21:58.000000000 -0500
@@ -4,8 +4,21 @@
 
 HADOOP_CONF_DIR=/etc/hadoop-0.20/conf
 HADOOP_HOME=/usr/lib/hadoop-0.20
+HADOOP_HDFS_HOME=$HADOOP_HOME
+HADOOP_COMMON_HOME=$HADOOP_HOME
+export GRIDFTP_HDFS_REPLICAS=2
 
-source $HADOOP_CONF_DIR/hadoop-env.sh
+#update for hadoop 2.0.0
+if [ -d "/etc/hadoop/conf" ]; then
+    HADOOP_CONF_DIR=/etc/hadoop/conf
+fi
+if [ -d "/usr/lib/hadoop" ]; then
+    HADOOP_HOME=/usr/lib/hadoop
+fi
+
+if [ -e "$HADOOP_CONF_DIR/hadoop-env.sh" ]; then
+    source $HADOOP_CONF_DIR/hadoop-env.sh
+fi
 
 if [ "x$JAVA_HOME" = "x" ]; then
 JAVA_HOME=/usr/java/default
@@ -39,10 +52,16 @@
 if [ -d "$HADOOP_HOME/webapps" ]; then
   CLASSPATH=${CLASSPATH}:$HADOOP_HOME
 fi
-for f in $HADOOP_HOME/hadoop-*-core.jar; do
+for f in $HADOOP_HOME/hadoop-*.jar; do
   CLASSPATH=${CLASSPATH}:$f;
 done
 
+if [ -d "$HADOOP_HOME/client" ]; then
+for f in $HADOOP_HOME/client/*.jar; do
+  CLASSPATH=${CLASSPATH}:$f;
+done
+fi
+
 # add libs to CLASSPATH
 for f in $HADOOP_HOME/lib/*.jar; do
   CLASSPATH=${CLASSPATH}:$f;
diff -ru gridftp-hdfs-0.5.4-orig/src/gridftp_hdfs.c gridftp-hdfs-0.5.4/src/gridftp_hdfs.c
--- gridftp-hdfs-0.5.4-orig/src/gridftp_hdfs.c	2012-07-19 10:39:34.000000000 -0500
+++ gridftp-hdfs-0.5.4/src/gridftp_hdfs.c	2012-07-19 11:05:28.000000000 -0500
@@ -259,7 +259,7 @@
     case GLOBUS_GFS_CMD_DELE:
 {
         errno = 0;
-        if (hdfsDelete(hdfs_handle->fs, PathName) == -1) {
+        if (hdfsDelete(hdfs_handle->fs, PathName,0) == -1) {
             if (errno) {
                 result = GlobusGFSErrorSystemError("unlink", errno);
             } else {
