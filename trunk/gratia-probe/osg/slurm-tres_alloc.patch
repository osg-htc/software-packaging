diff --git a/slurm/SlurmProbe.py b/slurm/SlurmProbe.py
index ad67a20..73f56e6 100644
--- a/slurm/SlurmProbe.py
+++ b/slurm/SlurmProbe.py
@@ -23,6 +23,7 @@ import gratia.common.Gratia as Gratia
 import MySQLdb
 import MySQLdb.cursors
 import re
+from distutils.version import LooseVersion
 
 prog_version = "%%%RPMVERSION%%%"
 prog_revision = '$Revision$'
@@ -84,7 +85,14 @@ class SlurmProbe:
         self.conn = self.get_db_conn()
 
         self.cluster = Gratia.Config.getConfigAttribute('SlurmCluster')
-        self.sacct = SlurmAcct(self.conn, self.cluster)
+
+        # SLURM made changes to the accounting database schema
+        if LooseVersion(self.get_slurm_version()) < LooseVersion("15.08.0"):
+            # Original schema
+            self.sacct = SlurmAcct_v1(self.conn, self.cluster)
+        else:
+            # Added TRES (Trackable resources) in 15.08.0pre5
+            self.sacct = SlurmAcct_v2(self.conn, self.cluster)
 
     def parse_opts(self):
         """Hook to parse command-line options"""
@@ -193,7 +201,7 @@ class SlurmCheckpoint(object):
 
     val = property(get_val, set_val)
 
-class SlurmAcct(object):
+class SlurmAcctBase(object):
     def __init__(self, conn, cluster):
         self._conn = conn
 
@@ -253,6 +261,8 @@ class SlurmAcct(object):
             # Set acct to info from NSS, or unknown
             r['acct'] = self._get_group(r['id_group'], 'unknown')
 
+class SlurmAcct_v1(SlurmAcctBase):
+
     def _users(self, where):
         cursor = self._conn.cursor()
 
@@ -341,3 +351,136 @@ class SlurmAcct(object):
             r['cluster'] = self._cluster
             self._addUserInfoIfMissing(r)
             yield r
+
+class SlurmAcct_v2(SlurmAcctBase):
+
+    def _parse_tres(self, tres):
+        """Parse SLURM database tres_alloc job data into dict"""
+        # SLURM 15 changed its job_table.cpus_alloc database column to tres_alloc
+        #    and converted the data to a comma separated list of "key=value" pairs
+        # Keys are defined in tres_types_t in src/common/slurmdb_defs.h
+        #    1 => CPU, 2 => MEM, 3 => ENERGY, 4 => NODE
+
+        ret = dict()
+
+        for item in tres.split(','):
+            # Skip blank entries
+            if not item:
+                continue
+
+            try:
+                k, v = item.split('=', 1)
+                ret[int(k)] = int(v)
+            except ValueError:
+                # TRES string is damaged? Continuing.
+                DebugPrint(1, "Error parsing TRES string '%s'" % tres)
+
+        return ret
+
+    def _users(self, where):
+        cursor = self._conn.cursor()
+
+        # Default GROUP_CONCAT() maximum length is 1024 chars
+        # Increase it to 64MB
+        cursor.execute('SET SESSION group_concat_max_len=64*1024*1024;');
+
+        # See enum job_states in slurm/slurm.h for state values
+        sql = '''SELECT j.id_user
+            , j.id_group
+            , (SELECT SUM(cpus_req)   FROM %(cluster)s_job_table WHERE
+                  id_user = j.id_user AND state IN (0,2)) AS cpus_pending
+            , (SELECT GROUP_CONCAT('|', tres_alloc) FROM %(cluster)s_job_table WHERE
+                  id_user = j.id_user AND state IN (1)  ) AS tres_alloc_list
+            , MAX(j.time_end) AS time_end
+            , a.acct
+            , a.user
+            FROM %(cluster)s_job_table as j
+            LEFT JOIN %(cluster)s_assoc_table AS a ON j.id_assoc = a.id_assoc
+            WHERE %(where)s
+            GROUP BY id_user
+            ORDER BY time_end
+        ''' % { 'cluster': self._cluster, 'where': where }
+
+        DebugPrint(5, "Executing SQL: %s" % sql)
+        cursor.execute(sql)
+
+        for r in cursor:
+            # Add handy data to job record
+            r['cluster'] = self._cluster
+
+            # Extract cpus_alloc from tres_alloc and sum to get cpus_running
+            # We were formerly relying on SQL to sum the cpus_alloc.
+            # Now we get a list of tres_alloc parameters, parse them, and sum
+            # the CPU count ourselves.
+            r['cpus_running'] = 0
+            if r['tres_alloc_list']:
+                for tres_txt in r['tres_alloc_list'].split('|'):
+                    tres = self._parse_tres(tres_txt)
+                    # tres_types_t.TRES_CPU = 1
+                    r['cpus_running'] += tres.get(1, 0)
+
+            # Return 0 instead of None where we don't have values
+            if r['cpus_pending'] is None:
+                r['cpus_pending'] = 0
+            self._addUserInfoIfMissing(r)
+            yield r
+
+    def _jobs(self, where, having = '1=1'):
+        cursor = self._conn.cursor()
+
+        # Note: When jobs are preempted, multiple cluster_job_table records
+        #       are inserted, each with distinct start and end times.
+        #       We consider the walltime to be the total time running,
+        #       adding up all the records.
+
+        sql = '''SELECT j.id_job
+            , j.exit_code
+            , j.id_group
+            , j.id_user
+            , j.job_name
+            , j.tres_alloc
+            , j.partition
+            , j.state
+            , MIN(j.time_start) AS time_start
+            , MAX(j.time_end) AS time_end
+            , SUM(j.time_suspended) AS time_suspended
+            , SUM(CASE WHEN j.time_end < j.time_start + j.time_suspended
+                       THEN 0
+                       ELSE j.time_end - j.time_start - j.time_suspended
+                  END) AS wall_time
+            , a.acct
+            , a.user
+            , ( SELECT MAX(s.max_rss)
+                FROM %(cluster)s_step_table s
+                WHERE s.job_db_inx = j.job_db_inx
+                /* Note: Will underreport mem for jobs with simultaneous steps */
+              ) AS max_rss
+            , ( SELECT SUM(s.user_sec) + SUM(s.user_usec/1000000)
+                FROM %(cluster)s_step_table s
+                WHERE s.job_db_inx = j.job_db_inx
+              ) AS cpu_user
+            , ( SELECT SUM(s.sys_sec) + SUM(s.sys_usec/1000000)
+                FROM %(cluster)s_step_table s
+                WHERE s.job_db_inx = j.job_db_inx
+              ) AS cpu_sys
+            FROM %(cluster)s_job_table as j
+            LEFT JOIN %(cluster)s_assoc_table AS a ON j.id_assoc = a.id_assoc
+            WHERE %(where)s
+            GROUP BY id_job
+            HAVING %(having)s
+            ORDER BY j.time_end
+        ''' % { 'cluster': self._cluster, 'where': where, 'having': having }
+
+        DebugPrint(5, "Executing SQL: %s" % sql)
+        cursor.execute(sql)
+
+        for r in cursor:
+            # Add handy data to job record
+            r['cluster'] = self._cluster
+
+            # Extract cpus_alloc from tres_alloc
+            tres = self._parse_tres(r['tres_alloc'])
+            r['cpus_alloc'] = tres.get(1, 0) # tres_types_t.TRES_CPU = 1
+
+            self._addUserInfoIfMissing(r)
+            yield r
