#! /bin/sh

#
# chkconfig: - 79 99
# description: Hadoop firstboot configuration
#
# hadoop configuration for the first time a node boots.  This should be
# run before the main hadoop boot script.
#

. /etc/rc.d/init.d/functions

# Set some defaults
REQUIRE_PUBLIC_HOSTNAME=1

. /etc/sysconfig/hadoop

# These will probably go away when we start requiring the settings
# to be in /etc/sysconfig.
HADOOP_NAMEPORT=${HADOOP_NAMEPORT-9000}
HADOOP_DATADIR=${HADOOP_DATADIR-/data1/hadoop}
HADOOP_DATA=${HADOOP_DATA-/data1/hadoop/data}
HADOOP_LOG=${HADOOP_LOG-/data1/hadoop/logs}
HADOOP_SCRATCH=${HADOOP_SCRATCH-/data1/hadoop/scratch}

start() {

    if [ -z "$HADOOP_NAMENODE" ] ; then
	echo "HADOOP_NAMENODE not defined.  Aborting."
        return 1
    fi

    if [ -z "$HADOOP_DATADIR" ] ; then
	echo "HADOOP_DATADIR not defined.  Aborting."
        return 1
    fi

    if [ "$HADOOP_GANGLIA_ADDRESS" == "" ] ; then
	if [ -e /etc/gmond.conf ] ; then
	    HADOOP_GANGLIA_ADDRESS=`grep -A 4 udp_send_channel /etc/gmond.conf | grep 'host\|mcast_join' | head -1 | sed -e 's/.*= //'`
	fi
    fi
    sed -i -e "s/servers=.*/servers=${HADOOP_GANGLIA_ADDRESS}:8649/" \
           -e "s/period=.*/period=${HADOOP_GANGLIA_INTERVAL}/" \
           -e "s/^# dfs\./dfs./" \
           -e "s/^# jvm\./jvm./" \
	   /etc/hadoop-0.20/conf/hadoop-metrics.properties

    if gmond -V 2>/dev/null | grep -q 'gmond 3.1' ; then
        sed -i -e 's/^#\(dfs.*GangliaContext31\)/\1/' \
               -e 's/^#\(jvm.*GangliaContext31\)/\1/' \
	   /etc/hadoop-0.20/conf/hadoop-metrics.properties
    else
        sed -i -e 's/^#\(dfs.*GangliaContext$\)/\1/' \
               -e 's/^#\(jvm.*GangliaContext$\)/\1/' \
	   /etc/hadoop-0.20/conf/hadoop-metrics.properties
    fi

    if [ "$HADOOP_NAMENODE_HEAP" != "" ] ; then
        sed -i -e "s/.*export HADOOP_HEAPSIZE=.*/export HADOOP_HEAPSIZE=${HADOOP_NAMENODE_HEAP}/" /etc/hadoop-0.20/conf/hadoop-env.sh
    fi

    sed -e "s#@HADOOP_CONF_DIR@#${HADOOP_CONF_DIR}#" \
           -e "s#@HADOOP_NAMENODE@#${HADOOP_NAMENODE}#" \
           -e "s#@HADOOP_NAMEPORT@#${HADOOP_NAMEPORT}#" \
           -e "s#@HADOOP_SCRATCH@#${HADOOP_SCRATCH}#" \
           -e "s#@HADOOP_LOG@#${HADOOP_LOG}#" \
           < /etc/hadoop-0.20/conf.osg/core-site.xml.in > /etc/hadoop-0.20/conf/core-site.xml

    sed -e "s#@HADOOP_CONF_DIR@#${HADOOP_CONF_DIR}#" \
           -e "s#@HADOOP_DATADIR@#${HADOOP_DATADIR}#" \
           -e "s#@HADOOP_DATA@#${HADOOP_DATA}#" \
           -e "s#@HADOOP_DATANODE_BLOCKSIZE@#${HADOOP_DATANODE_BLOCKSIZE}#" \
           -e "s#@HADOOP_REPLICATION_DEFAULT@#${HADOOP_REPLICATION_DEFAULT}#" \
           -e "s#@HADOOP_REPLICATION_MIN@#${HADOOP_REPLICATION_MIN}#" \
           -e "s#@HADOOP_REPLICATION_MAX@#${HADOOP_REPLICATION_MAX}#" \
           -e "s#@HADOOP_CHECKPOINT_DIRS@#${HADOOP_CHECKPOINT_DIRS}#" \
           -e "s#@HADOOP_PRIMARY_HTTP_ADDRESS@#${HADOOP_PRIMARY_HTTP_ADDRESS}#" \
           -e "s#@HADOOP_SECONDARY_HTTP_ADDRESS@#${HADOOP_SECONDARY_HTTP_ADDRESS}#" \
           -e "s#@HADOOP_CHECKPOINT_PERIOD@#${HADOOP_CHECKPOINT_PERIOD}#" \
           -e "s#@HADOOP_RACKAWARE_SCRIPT@#${HADOOP_RACK_AWARENESS_SCRIPT}#" \
           < /etc/hadoop-0.20/conf.osg/hdfs-site.xml.in > /etc/hadoop-0.20/conf/hdfs-site.xml

    sed -e "s#@HADOOP_CONF_DIR@#${HADOOP_CONF_DIR}#" \
           -e "s#@HADOOP_TRACKER@#${HADOOP_NAMENODE}#" \
           -e "s#@HADOOP_TRACKERPORT@#${HADOOP_NAMEPORT}#" \
           < /etc/hadoop-0.20/conf.osg/mapred-site.xml.in > /etc/hadoop-0.20/conf/mapred-site.xml

    # Add the syslog server, if any
    if [ "$HADOOP_SYSLOG_HOST" != "" ] ; then
        sed -i -e "s#log4j.appender.SYSLOG.SyslogHost=.*#log4j.appender.SYSLOG.SyslogHost=${HADOOP_SYSLOG_HOST}#" /etc/hadoop-0.20/conf/log4j.properties
    fi

    # Update /etc/fstab, if requested
    if [ "$HADOOP_UPDATE_FSTAB" == "1" ] ; then
        if [ ! -e /usr/bin/hdfs ] ; then
            echo "Not updating fstab because /usr/bin/hdfs not found.  Is hadoop-0.20-fuse installed?"
        fi
        mkdir -p /mnt/hadoop
        if grep -q '^hdfs#' /etc/fstab ; then
            sed -i -e "s;^hdfs#.*;hdfs# /mnt/hadoop fuse server=${HADOOP_NAMENODE},port=${HADOOP_NAMEPORT},rdbuffer=131072,allow_other 0 0;" /etc/fstab
        else
            echo "hdfs# /mnt/hadoop fuse server=${HADOOP_NAMENODE},port=${HADOOP_NAMEPORT},rdbuffer=131072,allow_other 0 0" >> /etc/fstab
        fi
    fi


    RETVAL=$?
    if [ $RETVAL != 0 ] ; then
        return $RETVAL
    fi

    chkconfig hadoop-firstboot off

    return 0
}

RETVAL=0

case $1 in
'start')
    start
    RETVAL=$?
    ;;
'reload')
    ;;
'status')
    ;;
'stop')
    ;;
'restart')
    ;;
*)
    echo "usage: $0 {start}"
    ;;
esac

exit $RETVAL
