#!/bin/sh
#
# /etc/init.d/hadoop - Start/stop the hadoop HDFS filesystem
#
# The following two lines allow this script to be managed by Fedora's
# chkconfig program.
#
# chkconfig: - 80 30
# description: hadoop is a cluster file system.

# Source function library.
. /etc/rc.d/init.d/functions

wait_for_process() {
for i in {1..10}
do
    if [ `/bin/hostname -s` == "$HADOOP_NAMENODE" ] ; then
        status -p "/var/run/hadoop/hadoop-$HADOOP_USER-namenode.pid" 'hadoop' > /dev/null
    elif [ `/bin/hostname -s` == "$HADOOP_SECONDARY_NAMENODE" ] ; then
        status -p "/var/run/hadoop/hadoop-$HADOOP_USER-secondarynamenode.pid" 'hadoop' > /dev/null
    else
        status -p "/var/run/hadoop/hadoop-$HADOOP_USER-datanode.pid" 'hadoop' > /dev/null
    fi
    STATUS=$?
    if [ "start" == "$1" ]; then
     if [ "$STATUS" -eq "0" ]; then
       RETVAL=0
       return 0
     fi
    fi
    if [ "stop" == "$1" ]; then
     if [ "$STATUS" -ne "0" ]; then
       RETVAL=0
       return 0
     fi
    fi
    sleep 1
done
RETVAL=1
return 1
}


if [ -e /etc/sysconfig/hadoop ] ; then
    . /etc/sysconfig/hadoop
fi

HADOOP_NAMEPORT=${HADOOP_NAMEPORT-9000}
HADOOP_DATADIR=${HADOOP_DATADIR-/data1/hadoop}
HADOOP_DATA=${HADOOP_DATA-/data1/hadoop/data}
HADOOP_SYSLOG=${HADOOP_SYSLOG-/var/log/hadoop/hadoop-syslog.log}
HADOOP_LOG=${HADOOP_LOG-/data1/hadoop/logs}
HADOOP_SCRATCH=${HADOOP_SCRATCH-/data1/hadoop/scratch}
POOL_DATA_SIZE_MIN=${HADOOP_MIN_DATANODE_SIZE-300}

LOCAL_NODENAME=`/bin/hostname -s`
if [ -z ${LOCAL_NODENAME} ] ; then
 echo "Unable to determine local node name."
 exit 1
fi
. /etc/hadoop/conf/hadoop-env.sh

setup_dirs() {
    mkdir -p $HADOOP_DATADIR
    mkdir -p $HADOOP_LOG
    mkdir -p $HADOOP_SCRATCH

    for dir in `echo "$HADOOP_DATA" | sed -e "s/,/ /g"` ; do
        mkdir -p $dir
        chown $HADOOP_USER: $dir
    done

    chown $HADOOP_USER: $HADOOP_DATADIR
    chown $HADOOP_USER: $HADOOP_LOG
    chown -R $HADOOP_USER: $HADOOP_SCRATCH

    chown $HADOOP_USER: /var/run/hadoop
}

start() {
        ulimit -n 65536
        # If namenode:
	if [ "${LOCAL_NODENAME}" == "$HADOOP_NAMENODE" ] ; then
            # Format the name node the first time it's used
            if [ ! -e $HADOOP_SCRATCH/dfs/name ] ; then
		nohup su "$HADOOP_USER" -s /bin/sh -c "/usr/bin/hadoop namenode -format" >> ${HADOOP_SYSLOG} 2>&1
	    fi
	    nohup su "$HADOOP_USER" -s /bin/sh -c "/usr/lib/hadoop/bin/hadoop-daemon.sh start namenode">> ${HADOOP_SYSLOG} 2>&1
        # If checkpoint server
	elif [ "${LOCAL_NODENAME}" == "$HADOOP_SECONDARY_NAMENODE" ] ; then
	    nohup su "$HADOOP_USER" -s /bin/sh -c "/usr/lib/hadoop/bin/hadoop-daemon.sh start secondarynamenode">> ${HADOOP_SYSLOG} 2>&1
	else
	    # A few sanity checks are needed before starting the data services
	    POOL_DATA_SIZE=`/usr/bin/getPoolSize $HADOOP_DATADIR`
	    if [ "$POOL_DATA_SIZE" == "0" ] ; then
		/usr/bin/logger -p daemon.err -t hadoop-firstboot "Hadoop not configured because pool size was zero."
		echo -n " ...$HADOOP_DATADIR has zero size?"
		return 1
	    fi
	    if [ $POOL_DATA_SIZE -lt "$POOL_DATA_SIZE_MIN"  ] ; then
		/usr/bin/logger -p daemon.err -t hadoop-firstboot "Hadoop not started because pool size was too small ($POOL_DATA_SIZE GB < ${POOL_DATA_SIZE_MIN} GB)"
		echo -n " ...$HADOOP_DATADIR is too small ($POOL_DATA_SIZE GB < ${POOL_DATA_SIZE_MIN} GB)"
		return 1
	    fi

	    nohup su "$HADOOP_USER" -s /bin/sh -c "/usr/lib/hadoop/bin/hadoop-daemon.sh start datanode">> ${HADOOP_SYSLOG} 2>&1
	fi

        RETVAL=$?
	if [ $RETVAL != 0 ] ; then
	    return $RETVAL
	else 
	    touch /var/lock/subsys/hadoop
	fi

	wait_for_process start
	return $RETVAL
	
}

# A function to stop a program.
stop() {
        # If namenode:
	if [ "${LOCAL_NODENAME}" == "$HADOOP_NAMENODE" ] ; then
	    su "$HADOOP_USER" -s /bin/sh -c "/usr/lib/hadoop/bin/hadoop-daemon.sh stop namenode"
	    RETVAL=$?
        elif [ "${LOCAL_NODENAME}" == "$HADOOP_SECONDARY_NAMENODE" ] ; then
            su "$HADOOP_USER" -s /bin/sh -c "/usr/lib/hadoop/bin/hadoop-daemon.sh stop secondarynamenode"
            RETVAL=$?
	else
	    su "$HADOOP_USER" -s /bin/sh -c "/usr/lib/hadoop/bin/hadoop-daemon.sh stop datanode"
	    RETVAL=$?
	fi

	if [ $RETVAL != 0 ] ; then
		return $RETVAL
	else 
	    rm -f /var/lock/subsys/hadoop
	fi

        wait_for_process stop
	return $RETVAL
	
}

prog="hadoop-daemon.sh"
name="hadoop-daemon.sh"

case $1 in 
'start')
        echo -n $"Starting $prog: "
        setup_dirs
	start
        RETVAL=$?
        if [ "$RETVAL" -eq "0" ]; then
		success
	else
		failure
	fi
	echo
	;;
'stop')
	echo -n $"Stopping $prog: "
	stop
        RETVAL=$?
        if [ "$RETVAL" -eq "0" ]; then
		success
	else
		failure
	fi
	echo
	;;
'status')
    # If namenode:
    if [ `/bin/hostname -s` == "$HADOOP_NAMENODE" ] ; then
        status -p "/var/run/hadoop/hadoop-$HADOOP_USER-namenode.pid" 'hadoop'
    elif [ `/bin/hostname -s` == "$HADOOP_SECONDARY_NAMENODE" ] ; then 
        status -p "/var/run/hadoop/hadoop-$HADOOP_USER-secondarynamenode.pid" 'hadoop'
    else
        status -p "/var/run/hadoop/hadoop-$HADOOP_USER-datanode.pid" 'hadoop'
    fi
    ;;
'reload' | 'restart')
	$0 stop
	$0 start
	;;
*)
	echo "usage: $0 {start|stop|status|restart}"
	;;
esac

exit $RETVAL
